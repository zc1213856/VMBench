# VMBenchÂ README

![title.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJMJEg6rjq3p8/img/666040a8-4ec1-474f-840e-f039539d7d08.png)

# ğŸ”¥Â Updates

*   \[3/2024\]Â **VMBench**Â evaluationÂ codeÂ &Â promptÂ setÂ released!
    

# ğŸ“£Â Overview

![overview.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJMJEg6rjq3p8/img/27919c5f-fcea-4f50-8ed8-835ede58b392.png)

Video generation has advanced rapidly, improving evaluation methods, yet assessing video's motion remains a major challenge. Specifically, there are two key issues: 1) current motion metrics do not fully align with human perceptions; 2) the existing motion prompts are limited. Based on these findings, we introduce **VMBench**---a comprehensive **V**ideo **M**otion **Bench**mark that has perception-aligned motion metrics and features the most diverse types of motion. VMBench has several appealing properties: (1) **Perception-Driven Motion Evaluation Metrics**, we identify five dimensions based on human perception in motion video assessment and develop fine-grained evaluation metrics, providing deeper insights into models' strengths and weaknesses in motion quality. (2) **Meta-Guided Motion Prompt Generation**, a structured method that extracts meta-information, generates diverse motion prompts with LLMs, and refines them through human-AI validation, resulting in a multi-level prompt library covering six key dynamic scene dimensions. (3) **Human-Aligned Validation Mechanism**, we provide human preference annotations to validate our benchmarks, with our metrics achieving an average 35.3% improvement in Spearmanâ€™s correlation over baseline methods. This is the first time that the quality of motion in videos has been evaluated from the perspective of human perception alignment. Additionally, we will soon release VMBench as an open-source benchmark, setting a new standard for evaluating and advancing motion generation models.

# ğŸ“ŠEvaluationÂ Results

## Gallery

**Prompt:**Â AÂ touristÂ joyfullyÂ splashesÂ waterÂ inÂ anÂ outdoorÂ swimmingÂ pool,Â theirÂ armsÂ andÂ legsÂ movingÂ energeticallyÂ asÂ theyÂ playfullyÂ splashÂ around.

|                       **CogVideoX-5B**                       |                       **HunyuanVideo**                       |                         **MochiÂ 1**                          |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| ![frame_0001](asset/frame_0001.jpg) | ![frame_0001](asset/frame_0001.jpg) |![frame_0001](asset/frame_0001.jpg) |
|                   **OpenSora-Plan-v1.3.0**                   |                      **OpenSora-v1.2**                       |                          **Wan2.1**                          |
| ![frame_0001](asset/frame_0001.jpg) | ![frame_0001](asset/frame_0001.jpg) | ![frame_0001](asset/frame_0001.jpg) |

**Prompt:**Â ThreeÂ booksÂ areÂ thrownÂ intoÂ theÂ air,Â theirÂ pagesÂ flutteringÂ asÂ theyÂ soarÂ overÂ theÂ soccerÂ field,Â landingÂ inÂ aÂ scatteredÂ pattern.

|     **CogVideoX-5B**     | **HunyuanVideo**  | **MochiÂ 1** |
| :----------------------: | :---------------: | :---------: |
| **OpenSora-Plan-v1.3.0** | **OpenSora-v1.2** | **Wan2.1**  |

**Prompt:**Â FourÂ flickeringÂ candlesÂ castÂ shadowsÂ asÂ theyÂ burnÂ steadilyÂ onÂ theÂ balcony,Â theirÂ flamesÂ dancingÂ withÂ theÂ gentleÂ breeze.

|     **CogVideoX-5B**     | **HunyuanVideo**  | **MochiÂ 1** |
| :----------------------: | :---------------: | :---------: |
| **OpenSora-Plan-v1.3.0** | **OpenSora-v1.2** | **Wan2.1**  |

**Prompt:**Â TwoÂ penguinsÂ waddleÂ alongÂ theÂ beach,Â occasionallyÂ stoppingÂ toÂ preenÂ theirÂ feathersÂ beforeÂ continuingÂ theirÂ journeyÂ acrossÂ theÂ oceanÂ shore.

|     **CogVideoX-5B**     | **HunyuanVideo**  | **MochiÂ 1** |
| :----------------------: | :---------------: | :---------: |
| **OpenSora-Plan-v1.3.0** | **OpenSora-v1.2** | **Wan2.1**  |

**Prompt:**Â InÂ theÂ bustlingÂ street,Â twoÂ kidsÂ runÂ towardsÂ aÂ smallÂ dog,Â bendingÂ downÂ toÂ carefullyÂ combÂ itsÂ fur,Â theirÂ handsÂ movingÂ swiftly.

|     **CogVideoX-5B**     | **HunyuanVideo**  | **MochiÂ 1** |
| :----------------------: | :---------------: | :---------: |
| **OpenSora-Plan-v1.3.0** | **OpenSora-v1.2** | **Wan2.1**  |

**Prompt:**Â InÂ theÂ garage,Â aÂ youngÂ girlÂ twirlsÂ gracefully,Â herÂ armsÂ outstretched,Â perfectlyÂ matchingÂ theÂ livelyÂ countryÂ lineÂ danceÂ beat.

|     **CogVideoX-5B**     | **HunyuanVideo**  | **MochiÂ 1** |
| :----------------------: | :---------------: | :---------: |
| **OpenSora-Plan-v1.3.0** | **OpenSora-v1.2** | **Wan2.1**  |

## QuantitativeÂ Results

*   [ ] æ¨¡å‹è¡¨ç°çš„äº”è¾¹å½¢å›¾
    

### VMBenchÂ Leaderboard

# ğŸ”¨Â Installation

## CreateÂ Environment

```shell
git clone https://github.com/Ran0618/VMBench.git
cd VMBench

# create conda environment
conda create -n VMBench python=3.10
pip install -r requirements.txt

# Install Grounded-Segment-Anything module
cd Grounded-Segment-Anything
python -m pip install -e segment_anything
pip install --no-build-isolation -e GroundingDINO
pip install -r requirements.txt
# Install Groudned-SAM-2 module
cd Grounded-SAM-2
pip install -e .

# Install Q-Align module
cd Q-Align
pip install -e .
```

## DownloadÂ checkpoints

# ğŸ”§Usage

FirstlyÂ sampleÂ videos,Â 

## SampleÂ Videos

*   [ ] PleaseÂ followÂ ourÂ `sample_demo.py`toÂ createÂ videos.Â 
    

## EvaluationÂ onÂ theÂ VMBench

### RunningÂ theÂ WholeÂ Pipeline

`bashÂ eval.sh`

### RunningÂ aÂ SingleÂ Metric

# â¤ï¸Acknowledgement

# ğŸ“œLicense

# âœï¸Citation